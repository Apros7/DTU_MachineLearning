{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"StandardizedDataFrameWithNansFilled.csv\", index_col=0)\n",
    "data[\"Status\"] = [1 if stat == \"Developed\" else 0 for stat in data[\"Status\"]]\n",
    "data.head()\n",
    "\n",
    "y = data['Life expectancy '].values\n",
    "y=y.T\n",
    "X_drop = data.drop(columns = ['Country','Year','Life expectancy '])\n",
    "\n",
    "\n",
    "# Add offset attribute\n",
    "attributeNames = X_drop.columns\n",
    "X_drop = np.concatenate((np.ones((X_drop.shape[0],1)),X_drop),1)\n",
    "attributeNames = [u'Offset']+attributeNames\n",
    "N, M = X_drop.shape\n",
    "X = X_drop\n",
    "\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 10\n",
    "CV = model_selection.KFold(K, shuffle=True)\n",
    "\n",
    "# Values of lambda\n",
    "lambdas = np.power(10.,range(-5,9))\n",
    "# Initialize variables\n",
    "\n",
    "#T = len(lambdas)\n",
    "Error_train = np.empty((K,1))\n",
    "Error_test = np.empty((K,1))\n",
    "Error_train_rlr = np.empty((K,1))\n",
    "Error_test_rlr = np.empty((K,1))\n",
    "Error_train_nofeatures = np.empty((K,1))\n",
    "Error_test_nofeatures = np.empty((K,1))\n",
    "w_rlr = np.empty((M,K))\n",
    "mu = np.empty((K, M-1))\n",
    "sigma = np.empty((K, M-1))\n",
    "w_noreg = np.empty((M,K))\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV.split(X,y):\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    internal_cross_validation = 10\n",
    "\n",
    "    Xty = X_train.T @ y_train\n",
    "    XtX = X_train.T @ X_train\n",
    "\n",
    "    # Compute mean squared error without using the input data at all\n",
    "    Error_train_nofeatures[k] = np.square(y_train-y_train.mean()).sum(axis=0)/y_train.shape[0]\n",
    "    Error_test_nofeatures[k] = np.square(y_test-y_test.mean()).sum(axis=0)/y_test.shape[0]\n",
    "\n",
    "    #opt_val_err, opt_lambda, mean_w_vs_lambda, train_err_vs_lambda, test_err_vs_lambda = rlr_validate(X_train, y_train, lambdas, internal_cross_validation)\n",
    "\n",
    "    k=0\n",
    "    lol =[]\n",
    "    lambs = []\n",
    "    for lamb in lambdas:\n",
    "\n",
    "        # Estimate weights for the value of lambda, on entire training set\n",
    "        lambdaI = lamb * np.eye(M)\n",
    "        lambdaI[0,0] = 0 # Do no regularize the bias term\n",
    "        w_rlr[:,k] = np.linalg.solve(XtX+lambdaI,Xty).squeeze()\n",
    "        # Compute mean squared error with regularization with lambda\n",
    "        lol.append(np.square(y_train-X_train @ w_rlr[:,k]).sum(axis=0)/y_train.shape[0])\n",
    "        Error_test_rlr[k] = np.square(y_test-X_test @ w_rlr[:,k]).sum(axis=0)/y_test.shape[0]\n",
    "        lambs.append(lamb)\n",
    "\n",
    "        # Display the results for the last cross-validation fold\n",
    "        k =+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04\n",
      " 1.e+05 1.e+06 1.e+07 1.e+08]\n",
      "[0.18049956531639913, 0.1804995653179755, 0.18049956547557727, 0.1804995811988003, 0.1805011172671959, 0.18062442007605595, 0.18353028159799772, 0.18901971143789556, 0.20143183799533876, 0.3949865599069311, 0.8429515488658708, 0.9786013606011248, 0.9947614533405652, 0.9964080416735585]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "s must be a scalar, or float array-like with the same size as x and y",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(lol)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m,\u001b[39m8\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(lambs,lol,\u001b[39m'\u001b[39;49m\u001b[39m.-\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# Don't plot the bias term\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mRegularization factor\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mMean Coefficient Values\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/02450/lib/python3.11/site-packages/matplotlib/pyplot.py:2862\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mscatter)\n\u001b[1;32m   2858\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[1;32m   2859\u001b[0m         x, y, s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, marker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2860\u001b[0m         vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, linewidths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[1;32m   2861\u001b[0m         edgecolors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plotnonfinite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2862\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mscatter(\n\u001b[1;32m   2863\u001b[0m         x, y, s\u001b[39m=\u001b[39;49ms, c\u001b[39m=\u001b[39;49mc, marker\u001b[39m=\u001b[39;49mmarker, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[1;32m   2864\u001b[0m         vmin\u001b[39m=\u001b[39;49mvmin, vmax\u001b[39m=\u001b[39;49mvmax, alpha\u001b[39m=\u001b[39;49malpha, linewidths\u001b[39m=\u001b[39;49mlinewidths,\n\u001b[1;32m   2865\u001b[0m         edgecolors\u001b[39m=\u001b[39;49medgecolors, plotnonfinite\u001b[39m=\u001b[39;49mplotnonfinite,\n\u001b[1;32m   2866\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2867\u001b[0m     sci(__ret)\n\u001b[1;32m   2868\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/envs/02450/lib/python3.11/site-packages/matplotlib/__init__.py:1446\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1444\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1445\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1446\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1448\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1449\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1450\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/02450/lib/python3.11/site-packages/matplotlib/axes/_axes.py:4587\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4583\u001b[0m s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mravel(s)\n\u001b[1;32m   4584\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(s) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m1\u001b[39m, x\u001b[39m.\u001b[39msize) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   4585\u001b[0m         (\u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(s\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   4586\u001b[0m          \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(s\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger))):\n\u001b[0;32m-> 4587\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   4588\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39ms must be a scalar, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4589\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor float array-like with the same size as x and y\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4591\u001b[0m \u001b[39m# get the original edgecolor the user passed before we normalize\u001b[39;00m\n\u001b[1;32m   4592\u001b[0m orig_edgecolor \u001b[39m=\u001b[39m edgecolors\n",
      "\u001b[0;31mValueError\u001b[0m: s must be a scalar, or float array-like with the same size as x and y"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAAKZCAYAAAA4fUHAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlkElEQVR4nO3df2zV9b348Veh0Kr3toswKwgy3NXJLhm7lMAot1l0WgOGG5LdwOKNqBeTNdsuAa7egdzoICbN3c3MvU7BLYJmCXobf8Y/eh3Nzb38EG4ymrIsQu4W4VrYWkkxa1F3i8Dn+4df+v32tiintC9AH4/k/HHee79P32d5r+7p55x+yoqiKAIAAAAYVWMu9gYAAADgs0CAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAgpIDfOfOnbF48eKYPHlylJWVxauvvvqJa3bs2BG1tbVRWVkZN9xwQzz11FPD2SsAAABctkoO8Pfffz9mzZoVTzzxxHnNP3z4cCxatCjq6+ujvb09HnrooVi5cmW89NJLJW8WAAAALldlRVEUw15cVhavvPJKLFmy5Jxzvv/978drr70WBw8e7B9rbGyMX/7yl7F3797h/mgAAAC4rJSP9g/Yu3dvNDQ0DBi74447YsuWLfHhhx/GuHHjBq3p6+uLvr6+/udnzpyJd999NyZMmBBlZWWjvWUAAAA+44qiiBMnTsTkyZNjzJiR+fNpox7gXV1dUVNTM2CspqYmTp06Fd3d3TFp0qRBa5qammLDhg2jvTUAAAD4WEeOHIkpU6aMyGuNeoBHxKCr1mc/9X6uq9nr1q2LNWvW9D/v6emJ66+/Po4cORJVVVWjt1EAAACIiN7e3pg6dWr88R//8Yi95qgH+LXXXhtdXV0Dxo4dOxbl5eUxYcKEIddUVFRERUXFoPGqqioBDgAAQJqR/Br0qN8HfP78+dHa2jpgbPv27TFnzpwhv/8NAAAAn0YlB/h7770X+/fvj/3790fER7cZ279/f3R0dETERx8fX758ef/8xsbGePvtt2PNmjVx8ODB2Lp1a2zZsiUeeOCBkXkHAAAAcBko+SPo+/bti1tuuaX/+dnvat9zzz3x7LPPRmdnZ3+MR0RMnz49WlpaYvXq1fHkk0/G5MmT4/HHH49vfvObI7B9AAAAuDxc0H3As/T29kZ1dXX09PT4DjgAAACjbjQ6dNS/Aw4AAAAIcAAAAEghwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEwwrwTZs2xfTp06OysjJqa2tj165dHzt/27ZtMWvWrLjyyitj0qRJcd9998Xx48eHtWEAAAC4HJUc4M3NzbFq1apYv359tLe3R319fSxcuDA6OjqGnL979+5Yvnx5rFixIt5888144YUX4he/+EXcf//9F7x5AAAAuFyUHOCPPfZYrFixIu6///6YMWNG/NM//VNMnTo1Nm/ePOT8//zP/4wvfOELsXLlypg+fXr8+Z//eXz729+Offv2XfDmAQAA4HJRUoCfPHky2traoqGhYcB4Q0ND7NmzZ8g1dXV1cfTo0WhpaYmiKOKdd96JF198Me68885z/py+vr7o7e0d8AAAAIDLWUkB3t3dHadPn46ampoB4zU1NdHV1TXkmrq6uti2bVssW7Ysxo8fH9dee2187nOfix//+Mfn/DlNTU1RXV3d/5g6dWop2wQAAIBLzrD+CFtZWdmA50VRDBo768CBA7Fy5cp4+OGHo62tLV5//fU4fPhwNDY2nvP1161bFz09Pf2PI0eODGebAAAAcMkoL2XyxIkTY+zYsYOudh87dmzQVfGzmpqaYsGCBfHggw9GRMRXvvKVuOqqq6K+vj4effTRmDRp0qA1FRUVUVFRUcrWAAAA4JJW0hXw8ePHR21tbbS2tg4Yb21tjbq6uiHXfPDBBzFmzMAfM3bs2Ij46Mo5AAAAfBaU/BH0NWvWxNNPPx1bt26NgwcPxurVq6Ojo6P/I+Xr1q2L5cuX989fvHhxvPzyy7F58+Y4dOhQvPHGG7Fy5cqYO3duTJ48eeTeCQAAAFzCSvoIekTEsmXL4vjx47Fx48bo7OyMmTNnRktLS0ybNi0iIjo7OwfcE/zee++NEydOxBNPPBF/+7d/G5/73Ofi1ltvjX/4h38YuXcBAAAAl7iy4jL4HHhvb29UV1dHT09PVFVVXeztAAAA8Ck3Gh06rL+CDgAAAJRGgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkGFaAb9q0KaZPnx6VlZVRW1sbu3bt+tj5fX19sX79+pg2bVpUVFTEF7/4xdi6deuwNgwAAACXo/JSFzQ3N8eqVati06ZNsWDBgvjJT34SCxcujAMHDsT1118/5JqlS5fGO++8E1u2bIk/+ZM/iWPHjsWpU6cuePMAAABwuSgriqIoZcG8efNi9uzZsXnz5v6xGTNmxJIlS6KpqWnQ/Ndffz2+9a1vxaFDh+Lqq68e1iZ7e3ujuro6enp6oqqqalivAQAAAOdrNDq0pI+gnzx5Mtra2qKhoWHAeENDQ+zZs2fINa+99lrMmTMnfvjDH8Z1110XN910UzzwwAPxhz/8Yfi7BgAAgMtMSR9B7+7ujtOnT0dNTc2A8Zqamujq6hpyzaFDh2L37t1RWVkZr7zySnR3d8d3vvOdePfdd8/5PfC+vr7o6+vrf97b21vKNgEAAOCSM6w/wlZWVjbgeVEUg8bOOnPmTJSVlcW2bdti7ty5sWjRonjsscfi2WefPedV8Kampqiuru5/TJ06dTjbBAAAgEtGSQE+ceLEGDt27KCr3ceOHRt0VfysSZMmxXXXXRfV1dX9YzNmzIiiKOLo0aNDrlm3bl309PT0P44cOVLKNgEAAOCSU1KAjx8/Pmpra6O1tXXAeGtra9TV1Q25ZsGCBfG73/0u3nvvvf6xX//61zFmzJiYMmXKkGsqKiqiqqpqwAMAAAAuZyV/BH3NmjXx9NNPx9atW+PgwYOxevXq6OjoiMbGxoj46Or18uXL++ffddddMWHChLjvvvviwIEDsXPnznjwwQfjr//6r+OKK64YuXcCAAAAl7CS7wO+bNmyOH78eGzcuDE6Oztj5syZ0dLSEtOmTYuIiM7Ozujo6Oif/0d/9EfR2toaf/M3fxNz5syJCRMmxNKlS+PRRx8duXcBAAAAl7iS7wN+MbgPOAAAAJku+n3AAQAAgOER4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkGFaAb9q0KaZPnx6VlZVRW1sbu3btOq91b7zxRpSXl8dXv/rV4fxYAAAAuGyVHODNzc2xatWqWL9+fbS3t0d9fX0sXLgwOjo6PnZdT09PLF++PL7xjW8Me7MAAABwuSoriqIoZcG8efNi9uzZsXnz5v6xGTNmxJIlS6Kpqemc6771rW/FjTfeGGPHjo1XX3019u/ff94/s7e3N6qrq6OnpyeqqqpK2S4AAACUbDQ6tKQr4CdPnoy2trZoaGgYMN7Q0BB79uw557pnnnkm3nrrrXjkkUfO6+f09fVFb2/vgAcAAABczkoK8O7u7jh9+nTU1NQMGK+pqYmurq4h1/zmN7+JtWvXxrZt26K8vPy8fk5TU1NUV1f3P6ZOnVrKNgEAAOCSM6w/wlZWVjbgeVEUg8YiIk6fPh133XVXbNiwIW666abzfv1169ZFT09P/+PIkSPD2SYAAABcMs7vkvT/NXHixBg7duygq93Hjh0bdFU8IuLEiROxb9++aG9vj+9973sREXHmzJkoiiLKy8tj+/btceuttw5aV1FRERUVFaVsDQAAAC5pJV0BHz9+fNTW1kZra+uA8dbW1qirqxs0v6qqKn71q1/F/v37+x+NjY3xpS99Kfbv3x/z5s27sN0DAADAZaKkK+AREWvWrIm777475syZE/Pnz4+f/vSn0dHREY2NjRHx0cfHf/vb38bPfvazGDNmTMycOXPA+muuuSYqKysHjQMAAMCnWckBvmzZsjh+/Hhs3LgxOjs7Y+bMmdHS0hLTpk2LiIjOzs5PvCc4AAAAfNaUfB/wi8F9wAEAAMh00e8DDgAAAAyPAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIMKwA37RpU0yfPj0qKyujtrY2du3adc65L7/8ctx+++3x+c9/PqqqqmL+/Pnx85//fNgbBgAAgMtRyQHe3Nwcq1ativXr10d7e3vU19fHwoULo6OjY8j5O3fujNtvvz1aWlqira0tbrnllli8eHG0t7df8OYBAADgclFWFEVRyoJ58+bF7NmzY/Pmzf1jM2bMiCVLlkRTU9N5vcaf/umfxrJly+Lhhx8+r/m9vb1RXV0dPT09UVVVVcp2AQAAoGSj0aElXQE/efJktLW1RUNDw4DxhoaG2LNnz3m9xpkzZ+LEiRNx9dVXn3NOX19f9Pb2DngAAADA5aykAO/u7o7Tp09HTU3NgPGampro6uo6r9f40Y9+FO+//34sXbr0nHOampqiurq6/zF16tRStgkAAACXnGH9EbaysrIBz4uiGDQ2lOeffz5+8IMfRHNzc1xzzTXnnLdu3bro6enpfxw5cmQ42wQAAIBLRnkpkydOnBhjx44ddLX72LFjg66K/2/Nzc2xYsWKeOGFF+K222772LkVFRVRUVFRytYAAADgklbSFfDx48dHbW1ttLa2DhhvbW2Nurq6c657/vnn4957743nnnsu7rzzzuHtFAAAAC5jJV0Bj4hYs2ZN3H333TFnzpyYP39+/PSnP42Ojo5obGyMiI8+Pv7b3/42fvazn0XER/G9fPny+Od//uf42te+1n/1/Iorrojq6uoRfCsAAABw6So5wJctWxbHjx+PjRs3RmdnZ8ycOTNaWlpi2rRpERHR2dk54J7gP/nJT+LUqVPx3e9+N7773e/2j99zzz3x7LPPXvg7AAAAgMtAyfcBvxjcBxwAAIBMF/0+4AAAAMDwCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABMMK8E2bNsX06dOjsrIyamtrY9euXR87f8eOHVFbWxuVlZVxww03xFNPPTWszQIAAMDlquQAb25ujlWrVsX69eujvb096uvrY+HChdHR0THk/MOHD8eiRYuivr4+2tvb46GHHoqVK1fGSy+9dMGbBwAAgMtFWVEURSkL5s2bF7Nnz47Nmzf3j82YMSOWLFkSTU1Ng+Z///vfj9deey0OHjzYP9bY2Bi//OUvY+/evef1M3t7e6O6ujp6enqiqqqqlO0CAABAyUajQ8tLmXzy5Mloa2uLtWvXDhhvaGiIPXv2DLlm79690dDQMGDsjjvuiC1btsSHH34Y48aNG7Smr68v+vr6+p/39PRExEf/BQAAAMBoO9ufJV6z/lglBXh3d3ecPn06ampqBozX1NREV1fXkGu6urqGnH/q1Kno7u6OSZMmDVrT1NQUGzZsGDQ+derUUrYLAAAAF+T48eNRXV09Iq9VUoCfVVZWNuB5URSDxj5p/lDjZ61bty7WrFnT//z3v/99TJs2LTo6OkbsjcOlpre3N6ZOnRpHjhzxVQs+tZxzPguccz4LnHM+C3p6euL666+Pq6++esRes6QAnzhxYowdO3bQ1e5jx44Nusp91rXXXjvk/PLy8pgwYcKQayoqKqKiomLQeHV1tf+B86lXVVXlnPOp55zzWeCc81ngnPNZMGbMyN29u6RXGj9+fNTW1kZra+uA8dbW1qirqxtyzfz58wfN3759e8yZM2fI738DAADAp1HJKb9mzZp4+umnY+vWrXHw4MFYvXp1dHR0RGNjY0R89PHx5cuX989vbGyMt99+O9asWRMHDx6MrVu3xpYtW+KBBx4YuXcBAAAAl7iSvwO+bNmyOH78eGzcuDE6Oztj5syZ0dLSEtOmTYuIiM7OzgH3BJ8+fXq0tLTE6tWr48knn4zJkyfH448/Ht/85jfP+2dWVFTEI488MuTH0uHTwjnns8A557PAOeezwDnns2A0znnJ9wEHAAAASjdy3yYHAAAAzkmAAwAAQAIBDgAAAAkEOAAAACS4ZAJ806ZNMX369KisrIza2trYtWvXx87fsWNH1NbWRmVlZdxwww3x1FNPJe0Uhq+Uc/7yyy/H7bffHp///Oejqqoq5s+fHz//+c8TdwvDU+rv87PeeOONKC8vj69+9auju0EYAaWe876+vli/fn1MmzYtKioq4otf/GJs3bo1abcwPKWe823btsWsWbPiyiuvjEmTJsV9990Xx48fT9otlGbnzp2xePHimDx5cpSVlcWrr776iWtGokEviQBvbm6OVatWxfr166O9vT3q6+tj4cKFA25n9v87fPhwLFq0KOrr66O9vT0eeuihWLlyZbz00kvJO4fzV+o537lzZ9x+++3R0tISbW1tccstt8TixYujvb09eedw/ko952f19PTE8uXL4xvf+EbSTmH4hnPOly5dGv/2b/8WW7Zsif/6r/+K559/Pm6++ebEXUNpSj3nu3fvjuXLl8eKFSvizTffjBdeeCF+8YtfxP3335+8czg/77//fsyaNSueeOKJ85o/Yg1aXALmzp1bNDY2Dhi7+eabi7Vr1w45/+/+7u+Km2++ecDYt7/97eJrX/vaqO0RLlSp53woX/7yl4sNGzaM9NZgxAz3nC9btqz4+7//++KRRx4pZs2aNYo7hAtX6jn/13/916K6uro4fvx4xvZgRJR6zv/xH/+xuOGGGwaMPf7448WUKVNGbY8wUiKieOWVVz52zkg16EW/An7y5Mloa2uLhoaGAeMNDQ2xZ8+eIdfs3bt30Pw77rgj9u3bFx9++OGo7RWGazjn/H87c+ZMnDhxIq6++urR2CJcsOGe82eeeSbeeuuteOSRR0Z7i3DBhnPOX3vttZgzZ0788Ic/jOuuuy5uuummeOCBB+IPf/hDxpahZMM553V1dXH06NFoaWmJoijinXfeiRdffDHuvPPOjC3DqBupBi0f6Y2Vqru7O06fPh01NTUDxmtqaqKrq2vINV1dXUPOP3XqVHR3d8ekSZNGbb8wHMM55//bj370o3j//fdj6dKlo7FFuGDDOee/+c1vYu3atbFr164oL7/o/0iCTzScc37o0KHYvXt3VFZWxiuvvBLd3d3xne98J959913fA+eSNJxzXldXF9u2bYtly5bF//zP/8SpU6fiL/7iL+LHP/5xxpZh1I1Ug170K+BnlZWVDXheFMWgsU+aP9Q4XEpKPednPf/88/GDH/wgmpub45prrhmt7cGION9zfvr06bjrrrtiw4YNcdNNN2VtD0ZEKb/Pz5w5E2VlZbFt27aYO3duLFq0KB577LF49tlnXQXnklbKOT9w4ECsXLkyHn744Whra4vXX389Dh8+HI2NjRlbhRQj0aAX/XLDxIkTY+zYsYP+bdqxY8cG/RuGs6699toh55eXl8eECRNGba8wXMM552c1NzfHihUr4oUXXojbbrttNLcJF6TUc37ixInYt29ftLe3x/e+972I+ChUiqKI8vLy2L59e9x6660pe4fzNZzf55MmTYrrrrsuqqur+8dmzJgRRVHE0aNH48YbbxzVPUOphnPOm5qaYsGCBfHggw9GRMRXvvKVuOqqq6K+vj4effRRn1DlsjdSDXrRr4CPHz8+amtro7W1dcB4a2tr1NXVDblm/vz5g+Zv37495syZE+PGjRu1vcJwDeecR3x05fvee++N5557zneouOSVes6rqqriV7/6Vezfv7//0djYGF/60pdi//79MW/evKytw3kbzu/zBQsWxO9+97t47733+sd+/etfx5gxY2LKlCmjul8YjuGc8w8++CDGjBmYFmPHjo2I/3eVEC5nI9agJf3JtlHyL//yL8W4ceOKLVu2FAcOHChWrVpVXHXVVcV///d/F0VRFGvXri3uvvvu/vmHDh0qrrzyymL16tXFgQMHii1bthTjxo0rXnzxxYv1FuATlXrOn3vuuaK8vLx48skni87Ozv7H73//+4v1FuATlXrO/zd/BZ3LQann/MSJE8WUKVOKv/zLvyzefPPNYseOHcWNN95Y3H///RfrLcAnKvWcP/PMM0V5eXmxadOm4q233ip2795dzJkzp5g7d+7FegvwsU6cOFG0t7cX7e3tRUQUjz32WNHe3l68/fbbRVGMXoNeEgFeFEXx5JNPFtOmTSvGjx9fzJ49u9ixY0f/f3bPPfcUX//61wfM/4//+I/iz/7sz4rx48cXX/jCF4rNmzcn7xhKV8o5//rXv15ExKDHPffck79xKEGpv8//fwKcy0Wp5/zgwYPFbbfdVlxxxRXFlClTijVr1hQffPBB8q6hNKWe88cff7z48pe/XFxxxRXFpEmTir/6q78qjh49mrxrOD///u///rH/X3u0GrSsKHwmBAAAAEbbRf8OOAAAAHwWCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAE/wdPFo57AkoCnQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    print(lambdas)\n",
    "    print(lol)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.scatter(lambs,lol,'.-') # Don't plot the bias term\n",
    "    plt.xlabel('Regularization factor')\n",
    "    plt.ylabel('Mean Coefficient Values')\n",
    "    plt.grid()\n",
    "\n",
    "    # You can choose to display the legend, but it's omitted for a cleaner \n",
    "    # plot, since there are many attributes\n",
    "    #legend(attributeNames[1:], loc='best')\n",
    "\n",
    "        \n",
    "        # To inspect the used indices, use these print statements\n",
    "        #print('Cross validation fold {0}/{1}:'.format(k+1,K))\n",
    "        #print('Train indices: {0}'.format(train_index))\n",
    "        #print('Test indices: {0}\\n'.format(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04\n",
      " 1.e+05 1.e+06 1.e+07 1.e+08]\n"
     ]
    }
   ],
   "source": [
    "   plt.figure(k, figsize=(12,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.(lambdas,mean_w_vs_lambda.T[:,1:],'.-') # Don't plot the bias term\n",
    "    plt.xlabel('Regularization factor')\n",
    "    plt.ylabel('Mean Coefficient Values')\n",
    "    plt.grid()\n",
    "    # You can choose to display the legend, but it's omitted for a cleaner \n",
    "    # plot, since there are many attributes\n",
    "    #legend(attributeNames[1:], loc='best')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Lambda: 1e{0}'.format(np.log10(lamb)))\n",
    "    plt.loglog(lambdas,train_err_vs_lambda.T,'b.-',lambdas,test_err_vs_lambda.T,'r.-')\n",
    "    plt.xlabel('Regularization factor')\n",
    "    plt.ylabel('Squared error (crossvalidation)')\n",
    "    plt.legend(['Train error','Validation error'])\n",
    "    plt.grid()\n",
    "        \n",
    "        # To inspect the used indices, use these print statements\n",
    "        #print('Cross validation fold {0}/{1}:'.format(k+1,K))\n",
    "        #print('Train indices: {0}'.format(train_index))\n",
    "        #print('Test indices: {0}\\n'.format(test_index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02450",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
